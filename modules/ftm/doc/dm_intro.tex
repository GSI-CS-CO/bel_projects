
\chapter{Introduction}
\glsresetall

%This document is part of the technical notes for the \gls{fair}. 

The new \gls{fair} facilities required a new \gls{cs}, which is currently implemented and tested as an upgrade to the facilities of the \gls{gsi}. This document described the real-time \gls{cs}, specifically the \gls{gmt}, as implemented and used in the 2019 beamtime. The primary focus lies on the \gls{dm}, which generates and distributes commands to be executed on the time-synchronised \gls{fec}s. 
\paragraph{}
This document is both a user manual for the \gls{fair} \gls{dm} and a collection of research and implementation documents. The latter are providing a deeper understanding of the \gls{dm}'s concepts, functions and algorithms. It also provides material for a hands on introduction to the tools and API. Chapter \ref{chap:userguide} is therefor written as a tutorial, meant as a quick start for anyone who needs to adminstrate or debug a \gls{dm}. The appendices contain additional information, tables and memory layout documentation complementing the doxygen documentation of the carpeDM source code.

\section{General Machine Timing}

The \gls{gmt} encopmpasses all \gls{rt} aspects of controlling accelerator hardware. The concept of \gls{rt} itself is often misinterpreted, as the term only means a requirement for determinism. A reaction has to occur within a defined timeframe of a stimulus, but it does not tell anything about how long this may take. In this context, \gls{rt} will always be understood as \enquote{hard real-time}. \enquote{Hard} means that data which has not been processed before its deadline is due, has no value anymore and is even considered dangerous. As an example, an autonomous car is a hard \gls{rt} system. A distance value from a sensor has little to no value it became available late, because the car's perception would be lagging behind physical reality. Likewise, the command to activate the breaks being late would make it useless. It would no longer fulfill the purpose of avoiding a collision.
\par
Deadline windows in the \gls{fair}-\gls{cs} vary depending on the device and assigned tasks, but as a rule of thumb, \gls{rt} units are expected to react somewhere in between the low millisecond to low microsecond range, with an accuracy in the nanosecond range. The \gls{rt} section of the \gls{fair}-\gls{cs} is currently undergoing an upgrade from older, \gls{mil}-bus based technology to the new \gls{wr} system. With it comes a change in paradigm, from event based to alarm based machine control.

\subsection{New vs Old Design Philosophy}
\label{ss:design_phil}
The underlying concept of the new \gls{gsi}/\gls{fair} \gls{cs} was to create an alarm based \gls{cs}, as opposed to the previous event based system.
The new architecture aims for accurate hard \gls{rt} control of machines, not influenced by the machine type, distance, controller form factor or interface type.
\paragraph{Old -- event based}
In an event based system such as in figure~\ref{fig:event_sys} the transmission time of an event is part of the control loop. An event is sent and the receiving system will carry out an action upon arrival. For multiple synchronous actions, multiple events must arrive
synchronously. This is usually achieved by matching signal propagation delays, either by matching cable lengths or introducing delays on the faster routes. The advantage lies in simplicity and low overhead during runtime; a form time synchronisation is not necessary. The downside lies in the network topology (i.e., its delays) being part of the event handling. This make configuration and expansion of the control network difficult, very hard to automate and time consuming.
\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/event_system}
   \caption{Event based System, Master (M) sends events to multiple slaves(S). Lines with lower delay (red) need to be compensated}
   \label{fig:event_sys}
\end{figure}
\paragraph{New -- alarm based}
In an alarm based system as shown in figure~\ref{fig:alarm_sys} on the other hand, all messages contain an absolute deadline (alarm), describing when they are to cause an action in the receiver. Upon reception, messages are stored until their alarm is due and their action is executed. For multiple synchronous actions, the lead time for message dispatch can be roughly chosen and just needs to be greater than the maximum possible transmission delay in the network. The great advantage is the ease of configuration due to the independence from transmission delays (temperature, network traffic, change of topology). This allows very high scalability, easy administration and very accurately synchronised actions.
\paragraph{} 
The downside of an alarm based system lies in the necessary complexity of senders and receivers. Clock oscillators and absolute time must be accurately synchronised between nodes and alarm messages require more complex protocol handling than events.
This also results in a higher price per receiver unit than an event based approach.
\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/alarm_system}
   \caption{Alarm based system. Master (M) sends messages to multiple slaves(S) in advance.  Line delay has no effect on timed message, node time must be synchronised.}
   \label{fig:alarm_sys}
\end{figure}
\newpage
\subsection{Responsibilities}
The new \gls{cs} design splits responsibilities for machine control into three distinct systems (see ~\ref{fig:cs_svs}).

\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/cs_svs}
   \caption{\gls{gsi}/\gls{fair} \gls{cs} Design}
   \label{fig:cs_svs}
\end{figure}

\paragraph{Settings Management} delivers sets of configuration values and curves to machines (frequency and phase settings for \gls{rf}, current ramps for magnets, etc). This requires large amounts of data and thus high bandwidth traffic, but the timeframe for delivery is relaxed. 
\paragraph{Timing} uses a separate, deterministic network to synchronise the local time and clock oscillators of master units and all endpoints on site. It allows a heterogenous \gls{tr} pool as well as arbitrary geographic and network topologies.
\paragraph{Command} uses the same network as timing and delivers command messages ahead of time to endpoints. Upon arrival, their alarm is queued and dedicated hardware modules guarantee action execution to \SI{1}{\nano\second} accuracy. Command can either directly control output ports or select machine data sets and order local firmware to handle execution.
\vspace{-1cm}
\section{Timing System and the Datamaster}
\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/stack}
   \caption{Schematic of the \gls{dm} components}
   \label{fig:stack}
\end{figure}
%
\subsection{Control System Stack}
The stack between \gls{lsa} and the timing network consists of a multitude of layers. The most important ones are the schedule parser, the graph model, syntactic and structural analysis, offline timing analysis, runtime control and validation, de/serialisation, \gls{hw} processing and network streaming.
Figure~\ref{fig:stack} shows the individual layers of the \gls{dm}, going from abstract to real-time from top to bottom. The high level connections to the \gls{lsa} and Director black boxes provide the input.
The Generator \gls{fesa} class, CarpeDM Library and \gls{eb} library all run on the \gls{dm} server (x86\_64), which runs a standard frontend Linux without real-time extensions. Layers below the host system run in programmable hardware and are real-time 
\gls{wr} capable. By default, the used \gls{tr} is PEXARIA V \gls{pcie} board. Access to the board's \gls{soc} is available via \gls{pcie}. carpeDM can also be connected to remote \gls{dm} hardware instead. The connection can be run over \gls{wr} network, over TCP, using the host platform as a \gls{sw} bridge (via socat) to \gls{pcie}. The Generator \gls{fesa} class and the \gls{eb} library will only briefly be described in this documentation. \gls{eb} is well documented already~\cite{123}, while the Generator 
\gls{fesa} class was intentionally designed as a \enquote{stupid} middleware wrapper for carpeDM. Apart from some additional logger and formatting code, all functionality is borrowed from the carpeDM library.


\subsection{Building Blocks}
\paragraph{High level}
\gls{lsa} is in essence a physics modelling framework for accelerators. A simplistic explanation is that models of accelerator components (physical properties of magnets, \gls{rf} cavities, power supplies\dots) and the desired beam properties are entered on one side, the necessary machine settings and command sequences come out on the other. The resulting actions are supposed to run in parallel, as alternative scenarios, or linked by a form of handshake.
As described in~\ref{ss:design_phil}, this needs both settings data, which is usually present in form of curves and tables, and a command sequence at runtime, choosing where which settings data set is to be used and how.
\gls{lsa}'s output to the timing system are \enquote{schedules}. These are small programs describing timing command generation, whose execution wihtin the \gls{dm} results in a stream of commands to timing receivers. Schedules are represented as graphs in carpeDM. To make it a good match to LSA content, this graph representation needed to be abstract, flexible and powerful. To make the \gls{dm}'s command distriubution deterministic however, the data structures used on the lower (embedded system) level needed to be simple and efficient. Lossless bidirectional translation between high level and low level representation was also a requirement.
\paragraph{Low level}
The \gls{dm} \gls{hw} is the embedded system in charge of creating the stream. There is a strong separation between the actual real-time sequencer,
which must never be disturbed from outside (no blocking calls) and the command interface. The \gls{dm} consists of multiple embedded \gls{cpu}s, each with their own independent \gls{ram}. To guarantee that the host does not block the \gls{dm} \gls{hw}, each \gls{ram} features two completely independent physical ports, removing bus access as a bottleneck. Using techniques borrowed from inter-thread communication models, the command module interacts with the realtime sequencer by message boxes and flags inside the \gls{dpram}.
\newpage
\section{Language for Accelerator Control}

carpeDM was designed as a domain specific language, using directed graphs to represent machine schedules at a high level. The language is not Turing-complete, but has distinguishing features very well suited for real-time control. carpeDM provides timely command generation and dispatch, conditional branches, nested loops, inter-process communication and realtime synchronisation. It was designed for extensive parallelism.
carpeDM also allows thread and transaction safe manipulation and replacement of partial schedules (subgraphs) at runtime. Future upgrades will include a full a-priori worst case analysis of processors loads, bus and network traffic to ensure
proper functionality even before machine schedules are executed.

\subsection{Schedule Graphs}
Schedule graphs are at the core of carpeDM, and this representation of a control program comes with two advantages. The first is that graph algorithms are a well researched field, which provides a rich set of tools to construct, search, manipulate and 
verify graphs. The second advantage is right in the name -- graphs are meant to be visualised, and visualisation helps understanding. 
\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/vis_dot_vs_neato}
   \caption{The same schedule graph shown in different visualiser settings. On the left: \emph{dot}, right: \emph{neato}. %Color indicates the machine, red \gls{sis18}, green \gls{esr}.
    }
   \label{fig:dot_vs_neato}
\end{figure}
\paragraph{Benefits of inbuilt visualisation}
Using the graphviz library and tools, there is a wide range of visualiser types and styles available. Figure~\ref{fig:dot_vs_neato} shows the same graph visualised with two different sample settings. The \emph{dot} visualiser on the left with its flow-chart like representations helps showing flow directions and dependencies and is well suited for debugging flows within a single control program. Others, such as \emph{neato} on the right, provide a more organic style, reminiscent of protein molecule structures and best suited for large graphs. This style is excellent for seeing the extent of wait loops, alternative scenarios and the interplay of multiple control programs and machines.
\subsection{Look, feel and function}
\begin{figure}[H]
   \centering
   \def\svgwidth{0.5\textwidth}
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/helloworld}
   \caption{Visualisation of Hello World Schedule Graph}
   \label{fig:hello}
\end{figure}
Shape and coloration are effective tools to further understanding. 
Let's have a look at the hello world example in figure~\ref{fig:hello}. There are two different node shapes there, rectangles and ovals. Ovals represent timing messages, rectangles are blocks, representing timespans and serve as decision points. The nodes are connected by directed edges (arrows), the edge colour represents relations between nodes. For example, a red arrow denotes an active path, black marks an inactive alternative path, blue leads to a communication target and so on. Likewise, node fill or frame colours are used as a visual aid. For example, a green fill is used to indicate that \gls{dm} embedded system has processed a node at least once. This painting of territory is often a great help in coverage tests and understanding the taken course through a schedule. A full legend of nodes, edge types and their appearance can be found at~\ref{ssec:bblocks}.
\paragraph{}
Another good example is the safe2remove module of carpeDM (see~\ref{chap:online-sched-mod}). It analyses the schedule runtime and determines if a given subgraph can safely be manipulated or removed. This is achieved by converting all activity in time into a time-invariant equivalency graph. The underlying verification algorithm is not trivial and its debug outputs are therefore complex. To just name a few examples, the analysis of the hierarchy of dynamic commands, found predominant paths, transformation log of inbuilt and runtime commands, extrapolated future safe states, contracts with the user regarding which queued commands must be preserved, safety assessment base on union and difference sets \dots{} the list of complex (even to developers) activity logs goes on. When a new feature is implemented, failed test cases need to be understood to correct errors, and doing this from a vast number of debug messages is difficult and time consuming.
\begin{figure}[H]
   \centering
   \includegraphics*[width=0.8\textwidth,keepaspectratio]{Figures/vis_debug}
   \caption{Visual style for validation of runtime subgraph changes %Color indicates the machine, red \gls{sis18}, green \gls{esr}.
    }
   \label{fig:vis_debug}
\end{figure} 
\paragraph{}
Visualised, however, the systems's actions and decision quickly become tangible: All dynamic activity is converted to edges of specific colours and pen styles. All nodes reachable from the subgraph via traversible edges are marked in red -- \emph{dangerous territory}.
The execution cursors are marked in blue -- \emph{important}. If no blue markers are inside in red territory, manipulating the subgraph has no negative impact and is allowed. If one or more are inside, manipulation would endanger the \gls{dm} embedded system and is forbidden. Simple.

\subsection{Graph translation for an embedded system}
carpeDM uses a simplified file system in the embedded level, inside which each graph node occupies (very small at \SI{52}{\byte}) page in memory, avoiding fragmentation while reaching near optimal memory utilisation. 
Such small sizes might seem odd, but one must keep in mind that \gls{ram} inside an \gls{fpga} is not like \gls{ram} inside a normal computer. It can be used highly compartmentalized and can be accessed truly parallel on a \gls{hw} level, but its size is extremely limited. The current \gls{dm} is limited to \SI{4}{\mega\byte}.
\paragraph{}
The graph structure is converted into binary structures. Directed graphs can easily be turned into linked lists, which work well in combination with the lean minimal file system.
All intelligence (and space) needed for memory management and transaction management is placed at the host side. The embedded sequencer can therefore follow a very simple design. It consists solely of a scheduler and several worker threads per CPU which follow pointers through linked lists of memory chunks representing the original graph.
Instead of a stack, the sequencer uses local storage queues for all dynamic change requests, one at each point of decision in the graph.
If it is be guaranteed that the communication queues are cleaned up after decisions are revoked at runtime, this distribution of control has several advantages~\cite[]{}. In particular, it allows fine control of subgraphs, which can be individually added or removed during runtime.
The current implementation also features a fast \gls{eb} runtime interface for other time critical devices in the control system, such as the UNILAC gateway or later, \gls{btb} control and machine protection.



%, but for now, we shall stick to the subset we saw here and have a first look the source code of the hello world example.
%
%\lstinputlisting[style=dotfiles, caption={Hello World Source Code}, label={lst:hello}]{Source/helloworld.dot}
%\paragraph{What you see}
%As their \emph{type} tags show, the lines starting with \emph{Evt\_PPS} declare the two timing messages this schedule generates. Their time offsets %are specified with the keyword \emph{toffs}:
%\SI{0}{\nano\second} and \SI{8}{\nano\second}. The line below, which starts with \emph{B\_PPS}, declares a block, and it also contains a time value,
%following the keyword \emph{tperiod}. This period (or duration) of the block is \SI{1e9}{\nano\second}, i.e. \SI{1}{\second}.
%This is equals the period with which the messages were generated. However, these are all timespans, while received events contained absolute points in %time. We will get to the translation rule in a moment(~\ref{})
%\par
%The last line specifies directed edges between the nodes. From the recurring node name, it becomes obvious they are made to form a loop. This %corresponds to the red arrows in figure~\ref{fig:hello}: Red edges are the \emph{default destinations},
%showing the successor of each node the \gls{dm} will take without outside intervention. It might seem strange at first that they do not have \emph{type%}, but wait\dots there is a line saying \emph{type="defdst"}, which is what we were looking for.
%Because default destinations are the most common edge types in most schedules, it makes sense to define a global default type to avoid clutter. This %works for all tags and can always be overridden locally (e.g. within an individual node or edge declaration). More details can be found under~\ref{}.
%\paragraph{What you get}
%
%The schedule execution will start at the pattern entry point, which is the node \emph{Evt\_PPS0}, and follow the edges from there.
%To get absolute execution times for all messages along the way, the \gls{dm} keeps a sum in each of its worker threads, consisting of the periods of %all processed blocks If a block is processed multiple times during loops, their period gets added multiple times, thus unrolling all loops and taken %branches. The execution times of messages are calculated
%by adding their offsets to the time sum. The start time, the absolute time the sum is initialised to, can either be supplied ($t_0>0$) or %automatically chosen ($t_0=0$) by the \gls{dm} depending on a flag (right now, next full second, etc).
%
%\paragraph{Example for HelloWorld}
%The time sum accumulates all blocks it comes past, so the sequence of execution times goes (assuming it started at $t=0$:
%\newline
%($\SI{0}{\second} + \SI{0}{\nano\second}, \SI{0}{\second} + \SI{8}{\nano\second}, \SI{1}{\second} + \SI{0}{\nano\second}, \SI{1}{\second} + \SI{8}{\%nano\second}, ~~\dots~~ , n \cdot \SI{1}{\second} + \SI{0}{\nano\second}, n \cdot \SI{1}{\second} + \SI{8}{\nano\second}$). Because the time sum is %absolute and offsets are relative, Blocks are necessary for repeating parts of a schedule.
%Otherwise, the realtive offsets would directly be interpreted as absolutes, placing all recurring messages at the exact same execution times, over and %over, until they all lie in the past.
%\paragraph{Need for rules}
%The above example explains why all sequences must be terminated by blocks. There are a handful more rules for schedule generation, a full list can be %found under~\ref{}.
%Don't worry, carpeDM checks the rules for you and will tell you off if you present it with bad schedules. It will even give you a (hopefully) %comprehensive error message as to why your schedule was rejected.
%Just one problem though: Typos and .dot language errors are the only errors you will be getting a line number for. Most checks for carpeDM are on an %abstract level, they can only be run \emph{after} your schedule was turned into a graph.
%At this point, there are no line numbers anymore, so you'll have to make do with the node/edge names when debugging your schedule.%