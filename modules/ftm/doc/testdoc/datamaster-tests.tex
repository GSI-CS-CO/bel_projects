\documentclass[12pt,a4paper]{report}
% Language: English
\pdfminorversion=7
\usepackage[pdftex]{graphicx}
\usepackage{changepage}
\usepackage{xcolor}
\usepackage{listings}

\lstdefinestyle{dotfiles}{
  escapeinside={(*@}{@*)}, % (*@\label{mylabel}@*)
  numbers=left,
  stepnumber=1,
  numberstyle=\tiny,
  numbersep=10pt,
  captionpos=b,
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  keepspaces=true,
  columns=flexible,
  language=C,
  showstringspaces=false,
  basicstyle=\scriptsize\ttfamily,
  keywordstyle=\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{red},
  tabsize=2,
  morekeywords={digraph, graph, subgraph, edge, node, color, style, shape, fillcolor},
}

\newcommand{\atSign}{{\fontfamily{ptm}\selectfont @}}

\newcommand{\ry}{\rotatebox{90}}
\begin{document}

\begin{titlepage}
\vspace{2cm}
\begin{center}
\Huge{Tests for the FAIR Datamaster}

\Large{Martin Skorsky}

\Large{Last change: 2024-10-02}
\end{center}
\vfill
\end{titlepage}

\tableofcontents

\chapter{Overview - What is tested}
The tests for the datamaster are written with Python and the pytest framework. This implies that tests can be started
by name and also with a name pattern to select a group of tests. The tests use the datamaster tools \texttt{dm-cmd}
and \texttt{dm-sched}.

The tests use the instance of the current build folder of the datamaster tools and \texttt{libcarpedm}.

All tests are on branch \texttt{dm-fallout-tests}. The tests run with \texttt{make} or \texttt{make all} in folder \texttt{modules/ftm/tests}.
To compile \texttt{libcarpedm} use \texttt{make prepare}. This runs \texttt{make clean} and \texttt{make} in folder \texttt{modules/ftm/ftmx86}.

Important: The tests need exclusive access to the datamaster and the timing receiver. Otherwise the schedules and timing messages may be not the ones to test.

Examples:

\texttt{OPTIONS='--runslow' make}

Run all tests against the local datamaster, even those marked with --runslow. These test take longer than usual tests.

\texttt{OPTIONS='--runslow -k test\_threadsStartStop' make}

Run tests with test\_threadsStartStop in the file name, the class name or the test method name. In this case it is a file name.

These two markers are allowed to skip some of the tests.
\begin{enumerate}
\item \texttt{--runslow} Tests marked with this marker are long running tests which slow down the over all execution time. If you add this marker to
the \texttt{OPTIONS}, these tests will run. Do not use it during test development.
\item \texttt{--development} Tests marked with this marker are not ready for automated testing. These are under development. If you add this marker
to the \texttt{OPTIONS}, these tests will run.
\end{enumerate}
Some test need both markers to run.

\begin{table}
\caption{Which test tests what (Part 1)\\ x means: this test uses the component, T means: this test tests this component.
For some tests the result is not checked.
These are considered as OK if no exception occurs.}
\centering
\begin{tabular}[t]{|l|r|c|c|c|c|c|c|c|c|}
\hline
Test                                    & \ry{number of tests } & \ry{Tools} & \ry{libcarpedm} & \ry{firmware} & \ry{uses Python} & \ry{checks result } \\ \hline
dmPerformance                           &                     &   x        &   T             &   x           &   -              &   -                 \\ \hline
test\_Cpu0Cpu1.py                       &  4                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_RunningThreads.py                 &  1                  &   -        &   -             &   -           &   x              &   x                 \\ \hline
test\_add.py                            &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_addDownloadCompare.py             &  238                &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_altDestinations.py                &  20                 &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_async.py                          &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_basic.py                          &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_blink.py                          &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_boosterStartthread.py             &  8                  &   x        &   T             &   T           &   x              &   x                 \\ \hline
test\_bpcStart.py                       &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_coupling.py                       &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_dmCmd.py                          &  31                 &   T        &   x             &   x           &   x              &   x                 \\ \hline
test\_dmCmdAbort.py                     &  3                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdAsyncclear.py                &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdClearcpudiag.py              &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdCursor.py                    &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdDeadlinePreptimeStarttime.py &  18                 &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdForce.py                     &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdHeap.py                      &  3                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdHex.py                       &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdNoop.py                      &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmCmdOrigin.py                    &  1                  &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_dmSched.py                        &  8                  &   T        &   x             &   x           &   x              &   x                 \\ \hline
test\_dmTestbench.py                    &  19                 &   T        &   x             &   x           &   x              &   x                 \\ \hline
test\_dmThreads.py                      &  33                 &   x        &   x             &   T           &   x              &   x                 \\ \hline
test\_environment.py                    &  3                  &   -        &   -             &   -           &   x              &   x                 \\ \hline
test\_fid.py                            &  3                  &   x        &   x             &   T           &   x              &   x                 \\ \hline
test\_flow.py                           &  5                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_flowpattern.py                    &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_flush.py                          &  24                 &   x        &   T             &   T           &   x              &   x                 \\ \hline
\end{tabular}
\end{table}

\begin{table}
\caption{Which test tests what (Part 2)\\ x means: this test uses the component, T means: this test tests this component.
For some tests the result is not checked.
These are considered as OK if no exception occurs.}
\centering
\begin{tabular}[t]{|l|r|c|c|c|c|c|c|c|c|}
\hline
Test                                    & \ry{number of tests } & \ry{Tools} & \ry{libcarpedm} & \ry{firmware} & \ry{uses Python} & \ry{checks result } \\ \hline
test\_loop.py                           &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_lzma.py                           &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_memory.py                         &  15                 &   T        &   T             &   T           &   x              &   x                 \\ \hline
test\_originStartthread.py              &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_originTwothreads.py               &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_overwrite.py                      &  3                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_overwriteQueue.py                 &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_parallelBranch.py                 &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_patternStartStop.py               &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_pps.py                            &  10                 &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_pps10Hz.py                        &  3                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_prioAndType.py                    &  2                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_priorityQueue.py                  &  2                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_referenceEdges.py                 &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_remove.py                         &  6                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_runAllSingle.py                   &  4                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_runCpu0Single.py                  &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_safe2remove.py                    &  19                 &   x        &   T             &   T           &   x              &   x                 \\ \hline
test\_schedules.py                      &  6                  &   x        &   x             &   T           &   x              &   -                 \\ \hline
test\_simultaneousThreads.py            &  3                  &   x        &   x             &   T           &   x              &   -                 \\ \hline
test\_singleEdgeTest.py                 &  1                  &   -        &   T             &   -           &   -              &   x                 \\ \hline
test\_startStopAbort.py                 &  2                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_switch.py                         &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
test\_unilac.py                         &  3                  &   x        &   x             &   T           &   x              &   x                 \\ \hline
test\_waitloopFlush.py                  &  1                  &   x        &   x             &   T           &   x              &   x                 \\ \hline
test\_zzzFinish.py                      &  1                  &   x        &   T             &   x           &   x              &   x                 \\ \hline
\end{tabular}
\end{table}

\chapter{The Tests}
\section{dmPerformance}
\texttt{dmPerformance} tests the performance improvements in libcarpedm.
The test starts a schedule on a clean datamaster, checks if some part of
the schedule is removable, removes it and then adds another schedule.
This is done for a small schedule and a larger schedule. The test is ok
if all commands work. There is no check for this.

\section{test\_Cpu0Cpu1.py}
\texttt{test\_Cpu0Cpu1.py} tests three cases where an edge connects nodes on two CPUs.

In the test \texttt{testTwoCpusFlow}, a flow node on CPU 0 connects with a target edge
and a flowdst edge to CPU 1. The test starts patterns, snoops the messages and checks that more than 35
messages were sent after one second. See Figure~\ref{fig:cpu0-1-flow-block-target}.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/cpu0-1-flow-block-target.pdf}
        \caption{A flow node on CPU 0 connects with a target edge to a block node on CPU 1}
        \label{fig:cpu0-1-flow-block-target}
    \end{figure}

In the test \texttt{testTwoCpusFlush}, a target edge and a flushovr edge connect CPU 0 and CPU 1.
The test starts patterns, snoops the messages and checks the messages after one second.
See Figure~\ref{fig:cpu0-1-flush-block-flushovr}.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/cpu0-1-flush-block-flushovr.pdf}
        \caption{A flush node on CPU 0 connects with a flushovr edge to a block node on CPU 1}
        \label{fig:cpu0-1-flush-block-flushovr}
    \end{figure}

In the test \texttt{testTwoCpusSwitch}, a switchdst edge and a target edge connect from CPU 0 to CPU 1.
The test starts patterns, snoops the messages and checks the messages after one second.
See Figure~\ref{fig:cpu0-1-switch-block-target}.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/cpu0-1-switch-block-target.pdf}
        \caption{A switch node on CPU 0 connects with a target edge to a block node on CPU 1}
        \label{fig:cpu0-1-switch-block-target}
    \end{figure}

In the test \texttt{testTwoCpusOrigin}, a origindst edge connects from CPU 0 to CPU 1.
The test tries to add the schedules, but this fails because such an edge is not allowed (neigbourhood validation forbids this).
See Figure~\ref{fig:cpu0-1-origin-block-origindst}.
    \begin{figure}
        \centering
        \includegraphics*[height=0.9\textheight,keepaspectratio]{TestPattern/cpu0-1-origin-block-origindst.pdf}
        \caption{A origin node on CPU 0 connects with an origindst edge to an event node on CPU 1}
        \label{fig:cpu0-1-origin-block-origindst}
    \end{figure}

Only for some node types and edge types it is allowed that source and target node run on different CPUs.

\section{test\_RunningThreads.py}
\texttt{test\_RunningThreads.py} is a test for development. The aim is to improve \texttt{prepareRunThreads}.
There were sporadic failures in the check that no thread is running. The command
\texttt{dm-cmd <datamaster> running} shows running threads, which is unexpected.
The test runs \texttt{prepareRunThreads} for 1000 times. The test adds some error handling and
statistics in \texttt{tearDown}. It is marked with \atSign{}pytest.mark.development, since this test is
not needed in test runs.

\section{test\_add.py}
\texttt{test\_add.py} contains one test that adds a schedule, adds a second schedule. Then download the
resulting schedule and compare this to an expected dot file. See Figure~\ref{fig:patternA-v1-v2}.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/patternA-v1-v2.pdf}
        \caption{The resulting schedule which is added in two steps.}
        \label{fig:patternA-v1-v2}
    \end{figure}

\section{test\_addDownloadCompare.py}
\texttt{test\_addDownloadCompare.py} test that a schedule is equivalent
to the schedule which is downloaded form the datamaster firmware.
The test steps are: clear the datamaster, add a schedule, start all
pattern, download the schedule, compare both schedules with
\texttt{scheduleCompare}. \texttt{scheduleCompare} should find no difference
between the original and the downloaded schedule. Each test case uses a
different schedule.

This test requires \texttt{scheduleCompare} to be installed. This tool
checks that two dot-files represent the same schedule. The tool is build
with make in folder modules/ftm/analysis/scheduleCompare/main/.
It is installed with sudo make install in the same folder.

\section{test\_altDestinations.py}
\texttt{test\_altDestinations} tests for 9 edges and 10 edges of type
\texttt{altdst} for a block node.
The schedule \texttt{altdst-flow-9.dot} has one block, nine flow commands
and nine messages. each flow command changes flow to another message.
The test adds this schedule and starts the pattern in this schedule.
The test checks that messages are produced.

The schedule \texttt{altdst-flow-10.dot} is similar to the one obove,
but with 10 flow nodes and 10 messages. Adding this schedule is OK.
The test checks for the correct response.

The schedule \texttt{altdst-9.dot} has one block and nine messages.
The test switches through all messages and checks with snoop that the
correct messages are send.

The schedule \texttt{altdst-10.dot} has one block and 10 messages.
This schedule can be added to the datamaster. The test checks for
the correct response.

The schedule \texttt{test-altdst-missing-node.dot} has one block with 9
altdst edges and one defdst edge. The test checks that a switch command
via CMD-schedule works.

\section{test\_async.py}
This test was \texttt{full\_test/dynamic/async}.
\begin{enumerate}
  \item Purpose of Test

  For a schedule asynchronous clear a block, change the destination to
  a timing message and check that all nodes are visited.

  See Figure~\ref{fig:Pattern_for_the_dynamic_async_test} for the test pattern.
  \item Test Actions

  Upload test schedule and start pattern $LOOP$. Check with \texttt{dm-cmd rawvisited}. The
  nodes 'BLOCK\_B', 'BLOCK\_LOOP', 'CMD\_LOOP' are visited. Lock pattern 'B' (this locks 'BLOCK\_B'), check this with
  \texttt{showlocks}. Clear pattern 'B' which clears the queues of 'BLOCK\_B', check this with \texttt{rawqueue}.
  Change schedule with flow command. Destination of 'BLOCK\_B' is now 'MSG\_A' for one message. Check this
  with \texttt{rawqueue}. Unlock pattern 'B', wait for $1.2$ seconds and then check with \texttt{rawvisited} that all
  nodes are visited and no blocks are locked (with \texttt{showlocks}).
    \begin{figure}
        \centering
        \includegraphics{TestPattern/dynamic_async.pdf}
        \caption{Pattern for the dynamic async test}
        \label{fig:Pattern_for_the_dynamic_async_test}
    \end{figure}
  \item Success Criteria

  Check that node 'MSG\_A' is visited after changing the destination of the flow.
\end{enumerate}
\section{test\_basic.py}
This test was \texttt{full\_test/static/basic}.
\begin{enumerate}
  \item Purpose of Test

  This test uses \texttt{dm-sched add} and \texttt{dm-sched remove}. The pattern Figure~\ref{fig:Pattern_for_the_static_basic_test}
  is loaded into datamaster and removed afterwards.

  \item Test Actions

  On a cleared datamaster the test pattern is added with \texttt{dm-sched add}. With \texttt{dm-sched status} it is checked
  that 24 nodes with the expected names are available. The test pattern is removed with \texttt{dm-sched remove}. At the
  end \texttt{dem-sched status} is used to check that no pattern is present on the datamaster.

    \begin{figure}
        \centering
        \includegraphics{TestPattern/static_basic.pdf}
        \caption{Pattern for the static basic test}
        \label{fig:Pattern_for_the_static_basic_test}
    \end{figure}
  \item Success Criteria

  The test is successful if no schedule is loaded. Checked with \texttt{dm-sched status}
\end{enumerate}

\section{test\_blink.py}
\begin{enumerate}
  \item Purpose of Test

  Test flow nodes in connection with origin, preptime and two threads.
  \item Test Actions

  Start pattern \texttt{ping} for a single timing message which indicates the start of the test.
  Set origin, preptime, starttime for threads 0, 1 of CPU 0. Read these values. Start thread 0, 1 of CPU 0
  with a single command. Snoop timing messages for 10 seconds and check the frequency of the messages.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/blink-download.pdf}
        \caption{Flip between two sequences of timing events}
        \label{fig:blink}
    \end{figure}
  \item Success Criteria

  The test is successful when snoop of timing messages receives all four types of messages, each marked by the parameter.
\end{enumerate}

\section{test\_boosterStartthread.py}
\texttt{test\_boosterStartthread.py} tests schedules with nodes of
type \texttt{origin} and type \texttt{startthread}.
\begin{enumerate}
\item \texttt{test\_threeThreads0}
Use schedule \texttt{booster\_startthread.dot} \\
 (see~\ref{fig:Schedule_booster_startthread-0}),
which has three pattern (MAIN, A, B). The schedule runs on CPU 1, thread 0.
It starts threads 1, 2, and 3. Thread 1 and 2 trigger a message with parameter 2,
while thread 3 triggers a message with paramter 3. The test result is
checked with a snoop for 1 second. The correct timeline of the messages
is not checked.
    \begin{figure}
        \centering
        \includegraphics*[width=0.9\textwidth,keepaspectratio]{TestPattern/booster_startthread-0-s.pdf}
        \caption{Schedule for test of origin and startthread with three
        threads, originated by three origin nodes}
        \label{fig:Schedule_booster_startthread-0}
    \end{figure}
\item \texttt{test\_threeThreads1}
Use schedule \texttt{booster\_startthread-1.dot} \\
(see~\ref{fig:Schedule_booster_startthread-1}) to test
origin nodes. The test starts pattern BOOST\_REQ and snoops timing messages
for two seconds. The result is checked for the event numbers
0x0100 (more than 7), 0x0200 (at least one), 0x0102 (exactly one),
0x0103 (exactly one), 0x0160 (at least one).
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/booster_startthread-1-s.pdf}
        \caption{Schedule for test of origin with thread 1}
        \label{fig:Schedule_booster_startthread-1}
    \end{figure}
\item \texttt{test\_threeThreads2}
Use schedule \texttt{booster\_startthread-2.dot} \\
(see~\ref{fig:Schedule_booster_startthread-2}) to test
origin nodes. The test starts pattern BOOST\_REQ and snoops timing messages
for three seconds. The result is checked for the event numbers
0x0100 (more than 7), 0x0200 (at least one), 0x0102 (exactly one),
0x0103 (exactly one), 0x0160 (at least one).
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/booster_startthread-2-s.pdf}
        \caption{Schedule for test of origin with thread 1}
        \label{fig:Schedule_booster_startthread-2}
    \end{figure}
\item \texttt{test\_threeThreads3}
Use schedule \texttt{booster\_startthread-3.dot} \\
(see~\ref{fig:Schedule_booster_startthread-3}),
to test origin and startthread nodes. The test starts pattern MAIN and snoops timing messages
for three seconds. The result is checked for the event numbers
0x0001 (at least one), 0x0002 (at least one), and 0x0003 (at least one).
Event number 0x0001 indicates thread 1, event number 0x0002 indicates thread 2, Event number 0x0003 indicates thread 3.
With saft-ctl snoop there are 4 timing messages each second after starting pattern MAIN.
First a message with evtno=0x0003, then two messages with evtno=0x0002 1µs later, one of these is delayed.
20µs later we get a message with evtno=0x0001.
tperiod=1s in block B\_MAIN defines the tact of one second. tperiod of the blocks B\_A and B\_B are not relevant.
The delay of evtno=0x0002 with 1µs is defined by toffs=1000. The delay of evtno=0x0001 is defined by toffs=20000.
What is the effect of toffs and startoffs defined in the three startthread nodes?
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/booster_startthread-3-s.pdf}
        \caption{Schedule for test of origin and startthread}
        \label{fig:Schedule_booster_startthread-3}
    \end{figure}
\item \texttt{test\_booster\_all\_threads}
Use schedule \texttt{booster-all-threads.dot} (see~\ref{fig:Schedule_booster_all_threads}),
which has one pattern MAIN.
    \begin{figure}
        \centering
        \includegraphics*[width=0.98\textwidth,keepaspectratio]{TestPattern/booster_all_threads-s.pdf}
        \caption{Schedule for test of origin and startthread with all 8 threads of CPU 0}
        \label{fig:Schedule_booster_all_threads}
    \end{figure}
The pattern runs on CPU 0, thread 0 and starts threads 1 to 7 on CPU 0.
MAIN has a timing message and a block in a loop. One timing message every 0.1 sec.
\item \texttt{test\_booster\_thread\_0\_loop}
Use schedule \\ \texttt{booster-thread-0-loop.dot} (see~\ref{fig:Schedule_booster_thread_0_loop}),
which has one pattern MAIN and starts thread 0 in a loop. This is a
theoretical setup to test that starting a running thread again does not
crash.
    \begin{figure}
        \centering
        \includegraphics*[width=0.7\textwidth,keepaspectratio]{TestPattern/booster_thread_0_loop-s.pdf}
        \caption{Schedule for startthread in a loop}
        \label{fig:Schedule_booster_thread_0_loop}
    \end{figure}
\item \texttt{test\_booster\_thread\_0}
The schedule consists of three nodes: a startthread for thread 0 (CPU 0), a timing message
with EVTNO 1, and a block with length 0.1 seconds. The thread 0 starts every 0.001 seconds again,
thus producing timing messages with 1kHz. The test asserts that there are more than
2990 tmsg in 3 seconds with EVTNO 0x0001. Use schedule \texttt{booster-thread-0.dot}
(see~\ref{fig:Schedule_booster_thread_0}), which has one pattern MAIN.
    \begin{figure}
        \centering
        \includegraphics*[width=0.55\textwidth,keepaspectratio]{TestPattern/booster_thread_0-s.pdf}
        \caption{Schedule for starting thread 0 once every 0.001 seconds}
        \label{fig:Schedule_booster_thread_0}
    \end{figure}
\item \texttt{test\_booster\_8\_loops}
The schedule consists mainly in a loop with origin nodes and startthread nodes for threads 1 to 7.
This loop runs in thread 0 with a block of length 0.1 seconds and a timing message with EVTNO 0, which
helps to control that the test is working. Each of the origin nodes is the origin of a sequence of a block,
a timing message, and a block (no loop). The startthread nodes start threads 1 to 7, repectively.
Since the EVTNO of the timing messages correspond to the thread numbers, the test can check that
the thread is started. Since there is no loop for thread 1 to 7 each of these threads runs to idle.
The threads are started once every 0.1 second from the main loop in thread 0. Thus we have a frequency of 10Hz
for the messages of each thread. This is checked with a snoop for 2 seconds.
Use schedule \\ \texttt{booster-8-loops.dot} (see~\ref{fig:Schedule_booster_8_loops}).
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/booster_8_loops.pdf}
        \caption{Schedule for starting threads 0 to 7 in a main loop}
        \label{fig:Schedule_booster_8_loops}
    \end{figure}
\end{enumerate}

\section{test\_bpcStart.py}
\texttt{test\_bpcStart.py} tests the implementation of the beam process chain start flag in libcarpedm.
The test schedule sends two timing messages with \\
\texttt{bpcstart=True} and \texttt{bpcstart=1}.
With \texttt{saft-ctl snoop} it is checked that the timing messages contain the correct setting.
In addition with \texttt{dm-sched} the dumped schedule is checked for the bpcstart flag.
\section{test\_coupling.py}
This test was \texttt{full\_test/dynamic/coupling}.
\begin{enumerate}
  \item Purpose of Test

  This test enlarges an existing pattern with a second pattern with edges into the first
  pattern. See Figure~\ref{fig:Pattern_for_the_static_coupling_test} for the test patterns.
  \item Test Actions

  First, a pattern with three nodes is added. In a second step a pattern with additional three nodes is added.
  This pattern contains edges into the first pattern.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/static_coupling1.pdf}
        \includegraphics{TestPattern/static_coupling2.pdf}
        \caption{Pattern for the static coupling test before and after coupling}
        \label{fig:Pattern_for_the_static_coupling_test}
    \end{figure}
  \item Success Criteria

  After adding the two patterns the status is checked with \texttt{dm-sched status}. The resulting \texttt{download.dot} is
  compared to an expected dot-file.
\end{enumerate}

\section{test\_dmCmd.py}
\texttt{test\_dmCmd.py} contains Python unit tests for the tool dm-cmd.
Each unit test calls dm-cmd with commands and options and checks the result
with the output on stdout and stderr. There are also negative tests with
an invalid command line. These tests are successful when the response is
the correct error message and not a core dump.

There are five tests for the stop command. The test cases are
\begin{enumerate}
\item Test with existing block with low prio queue: result ok.
\item Test with existing block without low prio queue: result fail.
\item Test with existing timing event: result fail.
\item Test with non-existing block: result fail.
\item Test with no target name: result fail.
\end{enumerate}

There are tests for \texttt{dm-cmd reset} and for \texttt{dm-cmd reset all}. These two tests check for
return code 0, but not the status of the datamaster.

\section{test\_dmCmdAbort.py}
\texttt{test\_dmCmdAbort.py} tests \texttt{dm-cmd $<$datamaster$>$ abort} for different CPUs and threads.
Mainly tests the options \texttt{-c} and \texttt{-t}.
\begin{enumerate}
\item testAbortSingleThreadDecimal tests this for each CPU and each thread, given as decimal numbers.
\item testAbortSingleThreadHex tests this for each CPU and each thread, given as hexadecimal numbers.
\item testAbortRunningThreads runs schedules on all threads and \texttt{abort}s for CPU 0 and 1 the threads 1, 3, 5, 7.
\end{enumerate}

\section{test\_dmCmdAsyncclear.py}
\texttt{test\_dmCmdAsyncclear.py} tests \texttt{dm-cmd $<$datamaster$>$ asyncclear} for different CPUs and threads.
Send the command \texttt{noop} to Block0b. Since the schedules send a message every second, this command is in the queue
for a second. The \texttt{asyncclear} clears this command in the queue. This is
checked with \texttt{dm-cmd $<$datamaster$>$ queue Block0b}. Before
\texttt{asyncclear} the command is in the queue, afterwards the queue is empty.

\section{test\_dmCmdClearcpudiag.py}
\texttt{test\_dmCmdClearcpudiag.py} tests the command \texttt{dm-cmd
$<$datamaster$>$ clearcpudiag} for different CPUs and threads.
Run \texttt{clearCPUdiag} for CPU 0 and 1 and for the threads 1, 3, 5, 7.
Check the result with \texttt{dm-cmd $<$datamaster$>$ diag}.

\section{test\_dmCmdCursor.py}
\texttt{test\_dmCmdCursor.py} tests \texttt{dm-cmd $<$datamaster$>$ cursor}
for two CPUs and four threads. Run \texttt{dm-cmd $<$datamaster$>$ cursor}
for CPU 0 and 1 and for the threads 1, 3, 5, 7.
Check for the correct number of output lines.

\section{test\_dmCmdDeadlinePreptimeStarttime.py}
\texttt{test\_dmCmdDeadlinePreptimeStarttime.py} tests the five commands \\
\texttt{dm-cmd $<$datamaster$>$ origin}, \\
\texttt{dm-cmd $<$datamaster$>$ cursor}, \\
\texttt{dm-cmd $<$datamaster$>$ deadline}, \\
\texttt{dm-cmd $<$datamaster$>$ preptime}, and \\
\texttt{dm-cmd $<$datamaster$>$ startline} \\
for different CPUs and threads.
Tests the commands \texttt{origin, cursor, starttime, preptime}, and
\texttt{deadline} for different combinations  of threads.
With \texttt{preptime}, all combinations for the threadbits between 0
and 255 ist tested. This is every subset of a
set of 8 threads. In addition, invalid thread masks and thread numbers
out of range are tested.

\section{test\_dmCmdForce.py}
\texttt{test\_dmCmdForce.py} tests the command \texttt{dm-cmd
$<$datamaster$>$ force} for different CPUs and threads.
Run \texttt{force} for CPU 0 and 1 and for the threads 1, 3, 5, 7.
Check for the correct number of output lines.

\section{test\_dmCmdHeap.py}
\texttt{test\_dmCmdHeap.py} tests \texttt{dm-cmd $<$datamaster$>$ heap}
for different CPUs and threads.
\begin{enumerate}
\item testHeapSingleThreadDecimal tests this for each CPU and each
thread, given as decimal numbers.
\item testHeapSingleThreadHex tests this for each CPU and each thread,
given as hexadecimal numbers.
\item testInspectHeap run \texttt{heap} for CPU 0 and 1 and for the
threads 1, 3, 5, 7. Check for the correct number of output lines.
Run \texttt{heap} for each thread on each CPU.
\end{enumerate}

\section{test\_dmCmdHex.py}
\texttt{test\_dmCmdHex.py} tests \texttt{dm-cmd $<$datamaster$>$ hex}
for the nodes \texttt{Block0a} and \texttt{Block0a\_ListDst\_0}. This
is done on a pps pattern on CPU0. The output is different for 8 and 32 threads.
The output is checked.

\section{test\_dmCmdNoop.py}
\texttt{test\_dmCmdNoop.py} tests \texttt{dm-cmd $<$datamaster$>$ noop} for different CPUs and threads.
Check with \texttt{dm-cmd $<$datamaster$>$ queue Block0b} that the queue of Block0b is empty.
Send the command \texttt{noop} to Block0b. Check with \texttt{dm-cmd $<$datamaster$>$ queue Block0b}
that the command \texttt{noop} is in the queue of Block0b.

\section{test\_dmCmdOrigin.py}
\texttt{test\_dmCmdOrigin.py} tests \texttt{dm-cmd $<$datamaster$>$ origin}
for two CPUs and four threads. Run \texttt{origin} for CPU 0 and 1 and for
the threads 1, 3, 5, 7. Check for the correct number of output lines.

\section{test\_dmSched.py}
\texttt{test\_dmSched.py} contains 8 unit tests for the tool dm-sched.
Each unit test calls dm-sched with commands and options and checks the
result with the output on stdout and stderr.

\begin{enumerate}
\item \texttt{dm-sched $<$datamaster$>$ -h}: check for correct usage message.
\item \texttt{dm-sched $<$datamaster$>$}: check for default operation (same as status).
\item \texttt{dm-sched $<$datamaster$>$ status}: check for printig the datamaster status.
\item \texttt{dm-sched $<$datamaster$>$ dump}: check that the current
schedule is dumped to file download.dot (the default file name).
\item \texttt{dm-sched $<$datamaster$>$ dump -o dump.dot}: check that
the current schedule is dumped to file dump.dot.
\item \texttt{dm-sched $<$datamaster$>$ clear}: check the clear command.
\item \texttt{dm-sched $<$datamaster$>$ rawvisited}: check the rawvisited command.
\item \texttt{dm-sched $<$datamaster$>$ add pps.dot}: check for adding a schedule.
\end{enumerate}

\section{test\_dmTestbench.py}
\begin{enumerate}
  \item Purpose of Test

  Tests the method analyseFrequencyFromCsv which is in
  the module dm\_testbench.py.
  \item Test Actions

  Run 8 tests for the different check syntax of this method with the
  file \texttt{other/snoop\_test\_analyseFrequencyFromCsv.csv}.
  \item Success Criteria

  Use the assertions in method analyseFrequencyFromCsv.
\end{enumerate}

\section{test\_dmThreads.py}
\texttt{test\_dmThreads.py} tests the firmware with up to 8 threads and up to 4 CPUs.
For each thread a pattern with one block and one timing message per second is
loaded and started. To check that the thread is running,
\texttt{dm-cmd} is used two times with a delay of one second. The number
of messages is extracted from stdout and this number must increase for test success.

There are 8 tests with 1 to 8 threads on CPU 0. In addition, one test runs
the schedules one 4 CPUs, each with 8 threads. This produces 32 messages per second.

\section{test\_environment.py}
\texttt{test\_environment.py} checks the test environment. The test is ok if and only if dm-cmd and dm-sched are
from folder ../bin and libcarpedm is loaded from ../lib. This is checked with \texttt{ldd}.

\section{test\_fid.py}
\texttt{test\_fid.py} tests timing messages with different values of fid.
\begin{enumerate}
\item \texttt{test\_fid7} tests the fix for the format id 7 bug. This bug
was: under some conditions an illegal format id 7 was in the message.
The test checks that ony format id 1 is in the snooped messages.
\item \texttt{test\_fid0} tests with fid 0, which results in 19 fields in the timing messages.
\item \texttt{test\_fid1} tests the standard format of the timing messages.
\end{enumerate}

\section{test\_flow.py}
This test is based on \texttt{full\_test/dynamic/branch/single}, using flow instead of flowcommand.
\begin{enumerate}
  \item Purpose of Test

  Test that the flow command switches from one block to another.

  See Figure~\ref{fig:Pattern_for_the_dynamic_branch_single_test} for the test pattern.
  \item Test Actions

  Add a schedule, start the pattern 'IN\_C0'. After checking that nodes 'BLOCK\_IN0' and 'BLOCK\_A' are visited,
        change the flow with the flow command at pattern 'IN\_C0' from 'A' to 'B'. Check that the flow
        command is in the low priority queue and then start the pattern 'IN\_C0'. Check that the flow
        command is processed in the low priority queue and node 'BLOCK\_B' is visited.

  Test the four combinations of relative VTIME, absolute VTIME and immediate vs. delayed (one second) execution.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/dynamic_branch_single.pdf}
        \caption{Pattern for the dynamic branch single test}
        \label{fig:Pattern_for_the_dynamic_branch_single_test}
    \end{figure}
  \item Success Criteria

  Changing flow from 'BLOCK\_A' to 'BLOCK\_B' works.
\end{enumerate}
\section{test\_flowpattern.py}
This test is based on \texttt{full\_test/dynamic/branch/single}.
\begin{enumerate}
  \item Purpose of Test

  Test that the flow command switches from one block to another.

  See Figure~\ref{fig:Pattern_for_the_dynamic_branch_single_test} for the test pattern.
  \item Test Actions

  Add a schedule, start the pattern 'IN\_C0'. After checking that nodes 'BLOCK\_IN0' and 'BLOCK\_A' are visited,
        change the flow with the flowpattern command at pattern 'IN\_C0' from 'A' to 'B'. Check that the flowpattern
        command is in the low priority queue and then start the pattern 'IN\_C0'. Check that the flowpattern
        command is processed in the low priority queue and node 'BLOCK\_B' is visited.

  Test the four combinations of relative VTIME, absolute VTIME and immediate vs. delayed (one second) execution.
  \item Success Criteria

  Changing flow from 'BLOCK\_A' to 'BLOCK\_B' works.
\end{enumerate}

\section{test\_flush.py}
Tests various variants of the flush command. The schedules use timing messages, flow and flush commands, and blocks.
The flow commands are used to fill the command queues of the block. They switch to different timing messages, which
differ in the parameter value.

Naming of the tests:
\texttt{test\_flow\_flushX\_prioY}, where
X are the queues to flush. Allowed values: None, 0, 1, 2, 01, 02, 12, 123.
Y is the priority of the flush. Allowed values: 0, 1, 2.
Naming of patterns:
P-queueX-prioY, where X and Y as described above.

Schedules used:\\
schedules/flush-queue01-prio0.dot\\
schedules/flush-queue01-prio1.dot\\
schedules/flush-queue01-prio2.dot\\
schedules/flush-queue23-prio0.dot\\
schedules/flush-queue23-prio1.dot\\
schedules/flush-queue23-prio2.dot

Structure of each test:
add the schedule, start the pattern twice. The second startpattern executes the commands which are written
to the queues on first startpattern.
Check for flushed queues and the executed flush command after a delay of 0.1 seconds.
Four tests use the same schedule to minimize the numer of schedules. Each schedule uses 4 CPUs.

\section{test\_loop.py}
This test was \texttt{full\_test/dynamic/loop}.
\begin{enumerate}
  \item Purpose of Test

        Test loop with flow initializer.

  See Figure~\ref{fig:Pattern_for_the_dynamic_loop_test} for the test pattern.
  \item Test Actions

        Add a schedule and start pattern 'IN\_A'. Check the visited nodes. Nodes 'INIT\_A0', 'BLOCK\_LOOP', and 'BLOCK\_EXIT'
        should be visited. Start pattern 'IN\_B' and check the visited nodes. All nodes should be visited.
    \begin{figure}
        \centering
        \includegraphics*[width=1.\textwidth,keepaspectratio]{TestPattern/dynamic_loop.pdf}
        \caption{Pattern for the dynamic loop test}
        \label{fig:Pattern_for_the_dynamic_loop_test}
    \end{figure}
  \item Success Criteria

  In the end all blocks are visited.
\end{enumerate}
\section{test\_lzma.py}
There is a bug in the lzma decompression methods. The memory is not correctly allocated.
This occurs with large schedules and long pattern names. The large schedule contains
a loop of timing messages connected to one block.

OK test (\texttt{test\_large\_patternname\_ok}): use a schedule with 862 messages and a pattern name of 30 chars.
This works without an exception, including start of pattern.

Fail test: use a schedule with 1000 messages and a pattern name of 30 chars.
This does not work. Ends with SEGV (return code -11).

\section{test\_memory.py}
There are 15 tests to tet the correct memory consumption of the schedules.
Oversized schedules schuld be rejected to prevent the datamaster being corrupted.

Four tests add two large schedule into the datamaster. This works fine.
Then a third schedule is loaded, in each test for a different CPU. This
should fail with return code 250.

Four additional tests check the memory limit more precisely. These tests
use generated schedules just with a given nuber of blocks. Each block
has its own pattern. A test with the theoretical limit of 1874 blocks
fails. A similar test with 1869 blocks is Ok, while a test with one
further block detects a failure. Also, a test with 1875 blocks detects a
failure. These four tests use CPU 0.

Two tests check the memory limit for all 4 CPUs. The OK-test loads 1869
blocks into CPU 0, 1, 2 and 1675 blocks into CPU 3. The Fail-test uses
one additional block on CPU 3.

A group of five tests (\texttt{test\_memory\_full\_msg\_*}) test the memory
with schedules with timing messages in a loop. Due to validation checks there
are 1000 messages in one loop allowed. The generator for the schedules
splits the timing messages into two loops when there are more than 1000 nodes.
\\ \texttt{test\_memory\_full\_msg\_small} uses 10 timing messages to test the generator.
\\ \texttt{test\_memory\_full\_msg\_half} uses 900 timing messages for the test.
\\ \texttt{test\_memory\_full\_msg\_ok} uses 1867 timing messages, which is the maximal number of nodes allowed.
\\ \texttt{test\_memory\_full\_msg\_infinite\_loop\_ok} uses 1000 timing messages. This is added and started.
\\ \texttt{test\_memory\_full\_msg\_infinite\_loop\_fail} uses 1001 timing
messages. \\ This schedule is rejected and not added.

\section{test\_originStartthread.py}
\begin{enumerate}
\item \texttt{test\_threadsStartStop} \\
Thread 0 assigns Tmsg\{1,2,3\} and Block\{1,2,3\} to thread 1,2,3 and starts these threads.
The test then starts pattern D (Tmsg4 and Block4) to show that this does not stop the other threads.
The test stops pattern A which stops thread 1.
The test stops pattern C which stops thread 3.
The test stops node Block2 which stops thread 2.
See Figure~\ref{fig:schedule_origin_startthreads} for the schedule. For the Tmsg and the Blocks the
diagram shows the threads. There is no command to stop a thread.
    \begin{figure}
        \centering
        \includegraphics*[width=1.\textwidth,keepaspectratio]{TestPattern/threadsStartStop.pdf}
        \caption{Schedule which assigns origins and then starts threads
        with these origins. This is used in test\_originStartthread.py}
        \label{fig:schedule_origin_startthreads}
    \end{figure}
\item \texttt{test\_nodeInTwoThreads} \\
This test demonstrates that a node can exist in two threads.
Tmsg1 ist in thread 1, Tmsg2 is in thread 2. Successor for both is Tmsg3.
Thus we have a timing message from Tmsg3 for each timing message from Tmsg1 and Tmsg2.
The loop in thread 0 (nodes Tmsg0, OriginN, StartthreadN, Block0) starts
thread 1 and 2 every 10ms. Thread 1 and 2 end with Block3.
See Figure~\ref{fig:schedule_nodeInTwoThreads} for the schedule.
    \begin{figure}
        \centering
        \includegraphics*[width=1.\textwidth,keepaspectratio]{TestPattern/nodeInTwoThreads.pdf}
        \caption{Schedule with a node in two threads. This is used in test\_originStartthread.py}
        \label{fig:schedule_nodeInTwoThreads}
    \end{figure}
\item \texttt{test\_startStopAllThreads} \\
    Run a pps pattern on all threads and all CPUs. Halt all threads and check this state.
    Then start four threads 0,1,2,3 on all CPUs and check.
    For more than 8 threads:
    Then start four threads 8,9,10,11 on all CPUs and check.
    Then start four threads 16,17,18,19 on all CPUs and check.
    Then start four threads 24,25,26,27 on all CPUs and check.
\item \texttt{test\_startStopBlocks} \\
    Run a pps pattern on all threads of CPU 0.
    Stop block Block0b four times and check the result. This block is on
    thread 1, and for more than 8 threads also on thread 9, 17, 25.
    Thus we check that one of these threads is stopped for more than
    8 threads.
\end{enumerate}

\section{test\_originTwothreads.py}
\begin{enumerate}
  \item Purpose of Test

  This test shows that an origin node and a startthread node work.
  \item Test Actions

  Origin and Start are in pattern B.
  Pattern B is started and produces with Tmsg1 events with parameter 1. Tmsg2 produces events with parameter 2.
  The node Start starts thread 1 and is the origin for this thread. Thus, thread 1 is started every 50 ms by itself.
  There is a snoop action for 1 s.
    \begin{figure}
        \centering
        \includegraphics*[width=0.65\textheight,keepaspectratio]{TestPattern/twothreads.pdf}
        \caption{Schedule with two threads used in test\_originTwothreads.py}
        \label{fig:schedule_twoThreads}
    \end{figure}
  \item Success Criteria

  The result of the snoop should get at least 15 events with parameter 1 and one message with parameter 2.
\end{enumerate}

\section{test\_overwrite.py}
\begin{enumerate}
\item testOverwrite1
    Load and start pattern A, a loop of a message and a block.
    Stop the pattern and overwrite the block with a blockalign.
    Analyse the timing messages with the parameter field.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite1-0.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite1-1.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite1-1-download.pdf}
        \caption{Schedules for testOverwrite1 (test\_overwrite.py). The first schedule
        consists of a block and an event. The parameter of the messages is 1,
        which is checked in the snooped messages. This pattern runs for a second.
        It is overwritten with the second schedule containing a blockalign and an event.
        This event sends parameter 2, which is also checked in the snooped messages.
        The third schedule is the result.}
        \label{fig:Schedules_for_testOverwrite1}
    \end{figure}

\item testOverwrite2
    Load a schedule with a switch. Executing the switch interchanges
    the defdst to EvtA with the altdst to EvtB. Then the schedule loops
    over EvtB.
    Overwrite the schedule with the original schedule changes the edges back
    to defdst to EvtA and altdst to EvtB. Then the switch is executed again.
    Analyse the timing messages with the parameter field.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite2-0.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite2-1-download.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/overwrite2-2-download.pdf}
        \caption{Schedules for testOverwrite2 (test\_overwrite.py). The first
        schedule shows the defdst to EvtA and the altdst to EvtB. After executing
        the switch, the second schedule shows the defdst to EvtB and the altdst to EvtA.
        Overwritting with the original scheulde results in the third schedule.}
        \label{fig:Schedules_for_testOverwrite2}
    \end{figure}

\item testOverwrite3
    Load a schedule with a switch. Executing the switch interchanges
    the defdst to EvtA with the altdst to EvtB. Then the schedule loops
    over EvtB.
    Overwrite the schedule with a smiliar schedule which replaces the switch
    with a flow and the switchdst edge with a flowdst edge.
    Analyse the timing messages with the parameter field.
    \begin{figure}
        \centering
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/overwrite3-0.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/overwrite3-0-download.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/overwrite3-1-download.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/overwrite3-1.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/overwrite3-2-download.pdf}
        \caption{Schedules for testOverwrite3 (test\_overwrite.py). The first schedule
        contains a switch. The second schedule is the check before executing the
        switch. The third schedule is the check after executing the
        switch. The fourth schedule overwrites the first
        with a flow node. The fifth schedule is the result.}
        \label{fig:Schedules_for_testOverwrite3}
    \end{figure}

\end{enumerate}

\section{test\_overwriteQueue.py}
The test \texttt{test\_overwriteSchedules} overwrites a block with a low priority
queue with a block that has a low and a high priority queue. The low priority
queue is always needed to stop the pattern PPS\_Q. The test is successful when
the downloaded schedules are isomorphic to the expected schedules with the
meta nodes. The messages are checked for the appropriate number of messages.
    \begin{figure}
        \centering
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/pps-no-queue.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/pps-qlo.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/pps-qlo-status.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/pps-qlo.pdf}
        \includegraphics*[height=0.28\textheight,keepaspectratio]{TestPattern/pps-qlo-status.pdf}
        \caption{Schedules for test\_overwriteSchedules (test\_overwriteQueue.py). The first schedule
        contains a block with no queue. The second overwrites this with a low priority queue.
        The result is the third schedule. The fourth schedule overwrites this with a block with
        two queues. The result is the fifth schedule.}
        \label{fig:Schedules_for_test_overwriteSchedules}
    \end{figure}

\section{test\_parallelBranch.py}
Use schedule \texttt{branch1.dot} to test branching with flow commands
with absolute time offset. The checks use snoop for specific event numbers.
The four tests are for CPU 0, CPU 0 and 1, CPU 0, 1, and 2, all 4 CPUs.
    \begin{figure}
        \centering
        \includegraphics*[width=\textwidth,keepaspectratio]{TestPattern/branch1.pdf}
        \caption{Schedule for test\_parallelBranch.py.}
        \label{fig:Pattern_for_test_parallelBranch}
    \end{figure}
    Each of these pattern A, B, C, D runs on a different CPU.

\section{test\_patternStartStop.py}
The test \texttt{test\_startStopPattern} runs a pps pattern on all threads of CPU 0.
    Stop pattern Block0b which should fail, since not a pattern name.
    Stop pattern PPS0b which is OK. This pattern runs on threads 1, 9, 17, 25
    (the last three for 32 threads). Check which thread is stopped.
    Start pattern Block0b which should fail, since not a pattern name.
    Start pattern PPS0b on the thread, which was stopped before. The start
    is OK. Check that all threads (8 or 32) are running.

\section{test\_pps.py}
\texttt{test\_pps.py} (pps: pulse per second) is a collection of tests based
on schedules with a simple loop of a timing message and a block.

\begin{enumerate}
\item test\_pps is a basic test with a
schedule which sends two timing messages every second. The test checks
with \texttt{saft-ctl snoop} the timing messages.

\item test\_ppsAdd is a basic test with a schedule which sends one timing
message every second. The test checks with \texttt{saft-ctl snoop} the timing
messages. Download the schedule with \texttt{dm-sched status} and compare
with the uploaded schedule with \texttt{scheduleCompare}. The two schedules
should be isomorphic.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-subgraph.pdf}
        \caption{Pattern for test\_ppsAdd.}
        \label{fig:Pattern_for_test_ppsAdd}
    \end{figure}

\item testPpsAdd0
    Add two schedules. The first schedule contains two nodes and an edge.
    The second adds some edges to the first schedule.
    Start pattern A and use a flow command to trigger messages.
    The status of the schedules is compared against known schedule files with
    \texttt{scheduleCompare}. The messages are snooped and checked.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test0-0.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test0-1-download.pdf}
        \caption{Schedules for testPpsAdd0 (test\_pps.py). The first produces
        one timing message. The second is the result after adding more edges.}
        \label{fig:Schedules_for_testPpsAdd0}
    \end{figure}
    During snoop start pattern A. This produces 1 message. Pattern A finishes.
    Download the schedule for later compare.
    Add a schedule which contains two edges.
    Queue a flow command with quantity 10 to block B\_A.
    Again start pattern A. The flow command triggers the next messages.
    At the end, 12 messages are produced and the pattern loops in block B\_A.

\item testPpsAdd1
    Add two schedules. The first schedule contains pattern A with two nodes and an edge.
    The second adds a similar pattern B.
    The messages are snooped and checked.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test1-0.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test1-1-download.pdf}
        \caption{Schedules for testPpsAdd1 (test\_pps.py).}
        \label{fig:Schedules_for_testPpsAdd1-0}
    \end{figure}

\item testPpsAdd2
    Test that the validation for nodes connected by defdst or altdst on
    the same CPU works. Add a first schedule. Try to add a second schedule.
    This fails due to an edge from CPU 0 to CPU 1.
    Add a third schedule with a target edge from CPU 0 to CPU 1. This works.
    \begin{figure}
        \centering
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test2-0.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test2-1.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test2-1-download.pdf}
        \includegraphics*[height=0.3\textheight,keepaspectratio]{TestPattern/pps-test2-2-download.pdf}
        \caption{Schedules for testPpsAdd2 (test\_pps.py). The upper part of the figure shows
        the first schedule on the left. Try to add the middle schedule. This fails, since block B\_A is on CPU 0
        but Evt\_B and B\_B are on CPU 1. The schedule on the right is the result. The lower part of the figure
        shows the result after adding a wait node W\_A with two blocks B\_B and B\_C to the original
        schedule of Evt\_A and B\_A.}
        \label{fig:Schedules_for_testPpsAdd2-0}
    \end{figure}

\item testPpsAdd3
    Test with five schedules.
    Add two schedules, remove the third, add the fourth, remove the fifth.
    \begin{figure}
        \centering
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-0.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-1.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-1-download.pdf}
        \caption{Schedules for testPpsAdd3 (test\_pps.py), first step. Starting with the upper left schedule,
        adding the upper right schedule results in the schedule in the lower part of the figure.}
        \label{fig:Schedules_for_testPpsAdd3-0}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-2.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-2-download.pdf}
        \caption{Schedules for testPpsAdd3 (test\_pps.py), second step. Remove the schedule with Evt\_B and B\_B results in the second schedule.}
        \label{fig:Schedules_for_testPpsAdd3-1}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-3.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-3-download.pdf}
        \caption{Schedules for testPpsAdd3 (test\_pps.py), third step. Add the schedule with Evt\_D and B\_D results in the second schedule.}
        \label{fig:Schedules_for_testPpsAdd3-2}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-4.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test3-4-download.pdf}
        \caption{Schedules for testPpsAdd3 (test\_pps.py), fourth step. Remove the first schedule results in the schedule with Evt\_D and B\_D.}
        \label{fig:Schedules_for_testPpsAdd3-3}
    \end{figure}

\item testPpsAdd4
    Test removing a pattern which is running. This is rejected as expected.
    Then stop the pattern A and remove it.
    Check that the appropriate number of messages is produced.
    \begin{figure}
        \centering
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test4-0.pdf}
        \includegraphics*[height=0.4\textheight,keepaspectratio]{TestPattern/pps-test4-1.pdf}
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test4-1-download.pdf}
        \caption{Schedules for testPpsAdd4 (test\_pps.py), first part. Removing the three nodes Evt\_A,
        B\_A, and B\_C from the first schedule fails since pattern A is running. The resulting
        schedule in the lower part is the same as the first schedule.}
        \label{fig:Schedules_for_testPpsAdd4-0}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test4-2.pdf}
        \includegraphics*[height=0.45\textheight,keepaspectratio]{TestPattern/pps-test4-2-download.pdf}
        \caption{Schedules for testPpsAdd4 (test\_pps.py), second part. After stopping pattern A, nodes
        Evt\_A and B\_A are removed and the result is the last schedule.}
        \label{fig:Schedules_for_testPpsAdd4-1}
    \end{figure}

\item testPpsAdd5
    Test removing a pattern which is running. This is rejected as expected.
    When pattern A has finished, remove it.
    Check that the appropriate number of messages is produced.
    \begin{figure}
        \centering
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test5-0.pdf}
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test5-1.pdf}
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test5-1-download.pdf}
        \includegraphics*[height=0.43\textheight,keepaspectratio]{TestPattern/pps-test5-2-download.pdf}
        \caption{Schedules for testPpsAdd5 (test\_pps.py). From the left upper schedule remove nodes
        Evt\_B and B\_B while pattern A is running. This fails with return code 250. Pattern A finishes.
        Trying to remove Evt\_B and B\_B again results in the lower right schedule with nodes Evt\_A and B\_A.}
        \label{fig:Schedules_for_testPpsAdd5-0}
    \end{figure}

\item testPpsAdd6
    Test adding a node which changes the pattern entry.
    Check that the appropriate number of messages is produced.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/pps-test6-0.pdf}
        \includegraphics{TestPattern/pps-test6-0-download.pdf}
        \includegraphics{TestPattern/pps-test6-1.pdf}
        \includegraphics{TestPattern/pps-test6-1-download.pdf}
        \caption{Schedules for testPpsAdd6 (test\_pps.py), first part. Start pattern A in the upper left schedule.
        The result is the upper right schedule. Overwrite the schedule with an altdst edge from
        BlockA to EvtA and no pattern entry. Result is the lower right schedule.
        Cannot start pattern, because entry is missing.}
        \label{fig:Schedules_for_testPpsAdd6-0}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics{TestPattern/pps-test6-2.pdf}
        \includegraphics{TestPattern/pps-test6-2-download.pdf}
        \caption{Schedules for testPpsAdd6 (test\_pps.py), second part.
        Add the left schedule with EvtB as pattern entry. Then start pattern A. This results in the right schedule.}
        \label{fig:Schedules_for_testPpsAdd6-1}
    \end{figure}

\item testPpsAdd8
    Test adding a schedule with a node with name ending in ListDst\_3. This fails,
    because this name is generated during upload and a collision happens.
    Second attempt is to add a similar schedule with the name Block0\_0\_ListDst\_6.
    This works. The generated nodes have the names Block0\_0\_ListDst\_x with x from 0 to 5.
    Download the schedule including meta nodes and compare it to the expected one with \texttt{scheduleCompare}.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/pps-test8-0.pdf}
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/pps-test8-1.pdf}
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/pps-test8-1-download.pdf}
        \caption{Schedules for testPpsAdd8 (test\_pps.py). The first one fails to load. The second
        is added successfully. Compare it with the third schedule.}
        \label{fig:Schedules_for_testPpsAdd8-0}
    \end{figure}

\end{enumerate}

\section{test\_prioAndType.py}
This test was \texttt{full\_test/static/prio\_and\_type}.
\begin{enumerate}
  \item Purpose of Test

The test checks the relative and the absolute time values for two nodes
in a four node pattern.
See Figure~\ref{fig:Pattern_for_the_static_priority_and_type_test} for
the test pattern and
\ref{fig:Pattern_for_the_static_priority_and_type_test_with_meta_nodes}
for the test pattern with meta nodes,
displaying the priority queues.
  \item Test Actions

  Add the pattern, check the relative time values. Clear the datamaster.
  Add the pattern again and check the absolute time values.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/static_prio_and_type.pdf}
        \caption{Pattern for the static priority and type test}
        \label{fig:Pattern_for_the_static_priority_and_type_test}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics*[height=0.95\textheight,keepaspectratio]{TestPattern/static_prio_and_type_meta.pdf}
        \caption{Pattern for the static priority and type test with meta nodes}
        \label{fig:Pattern_for_the_static_priority_and_type_test_with_meta_nodes}
    \end{figure}
  \item Success Criteria

  Two checks of the time values with \texttt{dm-cmd rawqueue}.
\end{enumerate}

\section{test\_priorityQueue.py}
\texttt{test\_priorityQueue.py} tests the execution of priority queues.

    Generate a schedule with 5 or 6 altdst edges to a central block.
    These edges connect this central block with tmsg nodes. The tmsg nodes
    have a defdst edge to the central block.

    With a generated schedule test altdst. Use a loop over all tmsg
    nodes to switch the destinations such that the schedule flow from the
    central block switches through all tmsg nodes. See Figure~\ref{fig:priorityQueue-5}
    \begin{figure}
        \centering
        \includegraphics*[width=0.95\textwidth,keepaspectratio]{TestPattern/priorityQueue-5.pdf}
        \caption{Pattern for the priority queue tests}
        \label{fig:priorityQueue-5}
    \end{figure}

\section{test\_referenceEdges.py}
\texttt{test\_referenceEdges.py} tests that reference edges work.
At most three reference edges are allowed for a node. testReferenceEdgeLoop1 uses 1 reference edge.
testReferenceEdgeLoop3 uses 3 reference edges. testReferenceEdgeLoop4 uses 4 reference edges, which is forbidden.

\begin{enumerate}
\item testReferenceEdgeSimple
    Use a schedule with an edge of type reference between two loops
    (a block and a tmsg). The loops run with 10Hz.
    Check for the correct parameter value when using the reference.
\item testReferenceEdgeLoop1
    Use a schedule with a loop of a block and two tmsg.
    The loops run with 1Hz. There is a reference between the two tmsg nodes.
    Check for the correct gid value in the timing messages.
    Check for the correct parameter value when using the reference.

\item testReferenceEdgeLoop3
    Use a schedule with a loop of a block and four tmsg.
    The loops run with 1Hz. There is are references between the tmsg nodes.
    Check for the correct gid value in the timing messages.
    Check for the correct parameter value when using the reference.
    See Figure~\ref{fig:testReferenceEdgeLoop3}.
    \begin{figure}
        \centering
        \includegraphics*[height=0.9\textheight,keepaspectratio]{TestPattern/reference-loop3.pdf}
        \caption{Schedule for testReferenceEdgeLoop3 (test\_referenceEdges.py).}
        \label{fig:testReferenceEdgeLoop3}
    \end{figure}
\item testReferenceEdgeLoop4
    Use a schedule with a loop of a block and five tmsg and four references.
    This is not allowed. Adding the schedule fails.
\end{enumerate}

\section{test\_remove.py}
\begin{enumerate}
\item testRemove1
    Load and during snoop start pattern A, a loop of a message and a
    block. This produces messages with 10Hz.
    Download the schedule for later compare.
    Stop the pattern and remove the pattern which is nearly the same, but
    the block has no type. The result is a schedule with only the block.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/remove1-0.pdf}
        \includegraphics{TestPattern/remove1-1.pdf}
        \includegraphics{TestPattern/remove1-1-download.pdf}
        \caption{Schedules for testRemove1 (test\_remove.py). The first schedule
        is the loop. The second schedule is removed from the first,
        resulting in the third schedule.}
        \label{fig:Schedules_for_testRemove1}
    \end{figure}

\item testRemove2
    Load and start pattern A, a loop of a message and a block.
    Stop the pattern and remove parts of the pattern which is nearly the same, but
    the block has no type and a different event node EvtC. Remove fails,
    because EvtC is unknown in the existing schedule.

    The difference to testRemove1 is that the schedule for removal contains
    EvtC instead of EvtA.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/remove2-0.pdf}
        \includegraphics{TestPattern/remove2-1.pdf}
        \includegraphics{TestPattern/remove2-1-download.pdf}
        \caption{Schedules for testRemove2 (test\_remove.py). The first schedule
        is the loop. The second schedule is removed from the first,
        resulting in the third schedule.}
        \label{fig:Schedules_for_testRemove2}
    \end{figure}

\item testRemove3
    Load and start pattern A, a loop of message EvtA and block BlockA.
    Stop the pattern and remove the pattern which is nearly the same, but
    the block BlockA has no type. The remove command fails.

    The difference to testRemove1 is that the schedule for removal contains
    EvtA without a type. Thus, the remove command tries to remove BlockA,
    which would leave EvtA childless.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/remove3-0.pdf}
        \includegraphics{TestPattern/remove3-1.pdf}
        \includegraphics{TestPattern/remove3-1-download.pdf}
        \caption{Schedules for testRemove3 (test\_remove.py). The first schedule
        is the loop. The second schedule is removed from the first,
        resulting in the third schedule.}
        \label{fig:Schedules_for_testRemove3}
    \end{figure}

\item testRemove4
    Load and start pattern A, a loop of message EvtA and block BlockA.
    Stop the pattern and remove EvtA. The result is a schedule with only
    the block. Then add node EvtA of type switch and block BlockB. Thus,
    EvtA changes the type.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/remove4-0.pdf}
        \includegraphics{TestPattern/remove4-1.pdf}
        \includegraphics{TestPattern/remove4-1-download.pdf}
        \caption{Schedules for testRemove4 (test\_remove.py). First part.
        First schedule consists of EvtA and BlockA. Remove the second schedule and get
        the third schedule as result.}
        \label{fig:Schedules_for_testRemove4-1}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics{TestPattern/remove4-2.pdf}
        \includegraphics{TestPattern/remove4-2-download.pdf}
        \caption{Schedules for testRemove4 (test\_remove.py). Second part.
        Add the first schedule with EvtA as a switch node. The result
        is the second schedule.}
        \label{fig:Schedules_for_testRemove4-2}
    \end{figure}

\end{enumerate}

\section{test\_runAllSingle.py}
This test was \texttt{full\_test/dynamic/basics/run\_all\_single}.
\begin{enumerate}
  \item Purpose of Test

    Run a very basic schedule on all four CPUs.

  See Figure~\ref{fig:Pattern_for_the_dynamic_run_all_test} for the test pattern.
  \item Test Actions

  Add a schedule with four blocks to the datamaster. For each CPU,
  check that no block is visited. Then start a pattern for one CPU and
  check that the block specific for this pattern is visited.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/dynamic_basic_run_all_single.pdf}
        \caption{Pattern for the dynamic run all test}
        \label{fig:Pattern_for_the_dynamic_run_all_test}
    \end{figure}
  \item Success Criteria

  For each pattern the correct CPU is used.
\end{enumerate}

\section{test\_runCpu0Single.py}
This test was \texttt{full\_test/dynamic/basics/run\_cpu0\_single}.
\begin{enumerate}
  \item Purpose of Test

    Add the test schedule to the datamaster, start patterns and check
    which nodes were visited.

  See Figure~\ref{fig:Pattern_for_the_dynamic_run_CPU_0_single_test}
  for the test pattern.
  \item Test Actions

    First check that no block is visited. Start pattern 'IN0'. Check
    that 'BLOCK\_A' and 'BLOCK\_IN0' are visited.
    Start pattern 'IN1'. Check that in addition 'BLOCK\_B' and
    'BLOCK\_IN1' are visited.
    \begin{figure}
        \centering
        \includegraphics{TestPattern/dynamic_basic_run_cpu0_single.pdf}
        \caption{Pattern for the dynamic run CPU 0 single test}
        \label{fig:Pattern_for_the_dynamic_run_CPU_0_single_test}
    \end{figure}
  \item Success Criteria

  In the end all blocks are visited.
\end{enumerate}

\section{test\_safe2remove.py}
\texttt{test\_safe2remove.py} tests to remove a pattern from a running schedule. Test steps:
\begin{enumerate}
\item Clear datamaster
\item Add schedule
\item Start pattern 'G1\_P1'
\item Check removal of one pattern, should fail while pattern is running.
\item Abort pattern 'G1\_P1'
\item Check removal of this pattern, should be valid, since pattern is not running.
\item Remove this pattern.
\item Check status of remaining schedule.
\end{enumerate}
These test steps are applied to a bunch of schedules.
The schedules use 1 to 4 CPUs whith 1, 2, 4, and 9 pattern beside the default pattern. There are 1, 10, or 150 blocks per pattern.

\section{test\_schedules.py}
\texttt{test\_schedules.py} collects schedules from INT or PROD. All patterns are started. The tests need 4 CPUs.
Tests that the schedules are compiled and loaded. This includes
two schedules from INT and PROD as of 2024-10-02.

\section{test\_simultaneousThreads.py}
\texttt{test\_simultaneousThreads.py} tests that startthread nodes can start a number of threads simultaneously.
In Figure~\ref{fig:Pattern_for_the_simultaneous_start_of_threads} StartThread (runs in thread 0) starts threads 1, 2, and 3.
To check that the threads are running, each threads produces timing messages with the thread number as parameter.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/simultaneousThreads4.pdf}
        \caption{Pattern for the simultaneous start of threads}
        \label{fig:Pattern_for_the_simultaneous_start_of_threads}
    \end{figure}
The tests run for two threads (0 and 1), four threads (0, 1, 2, 3) and all threads (8 or 32).

\include{singleEdgeTest}

\section{test\_startStopAbort.py}
This test was \texttt{full\_test/dynamic/basics/start\_stop\_abort}.
\begin{enumerate}
  \item Purpose of Test

    First part: Start and abort a pattern. Second part: Start and stop a pattern.

  See Figure~\ref{fig:Pattern_for_the_dynamic_start_stop_abort_test} for the test pattern.
  \item Test Actions

    Add a schedule, check that CPU 0 is idle and then start pattern 'IN\_C0'. Check that the pattern is running.
    Abort the pattern 'IN\_C0'. Check the visited nodes for the pattern. The second part is similar.
    Add the same schedule, check that CPU 0 is idle and then start pattern 'IN\_C0'. Check that the pattern is running.
    Stop the pattern 'IN\_C0'. Check the visited nodes for the pattern.
    \begin{figure}
        \centering
        \includegraphics*[width=1.0\textwidth,keepaspectratio]{TestPattern/dynamic_basic_start_stop_abort.pdf}
        \caption{Pattern for the dynamic start stop abort test}
        \label{fig:Pattern_for_the_dynamic_start_stop_abort_test}
    \end{figure}
  \item Success Criteria

  Check that pattern is correctly aborted (rawstatus RUN is 0 immediately) or
  stopped (rawstatus RUN is 1 immediately, but 0 after 1.5 seconds).
\end{enumerate}

\section{test\_switch.py}
This test was \texttt{full\_test/dynamic/switch}. The schedule \\
\texttt{dynamic-switch-schedule.dot} is used.
\begin{enumerate}
  \item Purpose of Test

  Test the switch command.
  \item Test Actions

  After loading the schedule check with 'dm-sched rawvisited' that no node
  is visited. Then start pattern IN0. Check the visited nodes. Then start
  pattern IN1 and check the visited nodes. Use a command schedule to
  switch to destination pattern B and check again the visited nodes.
  \item Success Criteria

  The correct nodes are visited after each step.
\end{enumerate}

\section{test\_unilac.py}
There are three tests with the same structure. The tests work with message rates of
5 kHz, 45kHz, 90 kHz.
\begin{enumerate}
  \item Purpose of Test

  This test is used to ensure that the datamaster can handle the amount of timming messages
  needed to control UNILAC. This should be at least 600 messages in a 20 msec intervall. This
  is a message rate of 30 kHz.
  \item Test Actions
  The schedule consists of two series of timing messages which are numbered by evtno and parameter.
  At the end of the first series a flow command directs the flow to the second series of timing messages.
  The block has a length of 10 msec, so it is executed with 100 Hz.
    \begin{figure}
        \centering
        \includegraphics*[width=0.95\textwidth,keepaspectratio]{TestPattern/unilac100.pdf}
        \caption{Schedule to test the message rate for the UNILAC}
        \label{fig:unilac100}
    \end{figure}
  \item Success Criteria

  Mesages with parameter 1 are received by saft-ctl snoop with 50 Hz.
\end{enumerate}

\section{test\_waitloopFlush.py}
\texttt{test\_waitloopFlush.py} uses a schedule with a wait loop to check
the correctness of the flush command. The schedule contains BLOCK\_LOOP with a low
prio queue and a high prio queue. On pattern start, a flow command is queue in
the low prio queue with quantity 10,000. This redirects the pattern to
BLOCK\_LOOP such that this block is executed 10,000 times in a loop. Also
on start of pattern, a flush command is queued in the high prio queue with a
relative valid time of 0.5 seconds. Since BLOCK\_LOOP has a period of 100 µs,
the flush command breaks the loop after 5011 executions.

The test checks after 0.1 seconds that the flush is not executed, but after 1 second
it is executed. The timeline of the checks is not precise enough to check
exactly after 0.5 seconds the execution.

\section{test\_zzzFinish.py}
\texttt{test\_pps.py} (pps: pulse per second) is a basic test with a
schedule which sends two timing messages every second. The test checks
with 'saft-ctl snoop' the timing messages. This test should be the last
in the whole test suite to leave the datamaster with a defined schedule.

\chapter{Common Components - The Testbench}
\section{dm\_testbench.py}
\texttt{dm\_testbench.py} is a collection of Python functions for use
in other test scripts.
\begin{enumerate}
\item setUpClass(self)

Read environment variables for the datamaster and the test binaries.
\begin{itemize}
\item TEST\_BINARY\_DM\_CMD sets the binary for dm-cmd. Default is just
\texttt{dm-cmd}, the installed tool.
\item TEST\_BINARY\_DM\_SCHED sets the binary for dm-sched. Default is just
\texttt{dm-sched}, the installed tool.
\item DATAMASTER set the datamaster device. Example: \texttt{dev/wbm0} or
\texttt{tcp/fel0069.acc}. There is no default. This method stops with a
KeyError if the environment variable DATAMASTER is not set.
\item TEST\_SCHEDULES set the folder for schedules. Default is \\
 \texttt{schedules/}.
\item SNOOP\_COMMAND set the snoop command. Default is \\
\texttt{saft-ctl tr0 -xv snoop 0 0 0}.
\end{itemize}
Usually the binaries for dm-cmd and dm-sched together with the libcarpedm
are used from the build of the test repository in folders \\
\texttt{modules/ftm/bin} and \texttt{modules/ftm/lib}. This is
configured in the Makefile.

Set the thread quantity (read from the lm32 firmware with eb-info) and
set the CPU quantity to 4.

\item setUp(self)

Call \texttt{self.initDatamaster()}.
\item initDatamaster(self)

The datamaster is halted, cleared, and statistics is reset with
\texttt{dm-cmd reset all}.
\item addSchedule(self, scheduleFile)

Add the \texttt{scheduleFile} to the datamaster with the command
\texttt{dm-sched DATAMASTER add scheduleFile}. Does not start a pattern.
\item startPattern(self, scheduleFile)

Connect to the given datamaster and load the schedule file (dot format).
Search for the first pattern in the datamaster with 'dm-sched' and start it.
\item startPattern(self, scheduleFile, pattern='')

Add the \texttt{scheduleFile} to the datamaster with the command
\texttt{dm-sched DATAMASTER add scheduleFile}. Start the given pattern.
The default for the pattern name is empty.
\item startAllPattern(self, scheduleFile, pattern='', onePattern=False,\\ start=True)

Connect to the given datamaster and load the schedule file (dot format).
If a pattern is given, start this pattern.
Otherwise, scan the output of dm-sched for pattern names and start the
first pattern (onePattern = True) or all pattern (onePattern = False).
All calls to dm-cmd and dm-sched are checked for the return code. The method
stops of the return code is not 0.

\item startAndCheckSubprocess(self, argumentsList, expectedReturnCode =
[0], linesCout=-1, linesCerr=-1)

Start a subprocess and check the return code and the lines of stdout
and stderr. The output on stdout or stderr is lost.
\begin{enumerate}
\item argumentsList

The command itself with arguments as a list.
\item expectedReturnCode = [0]

The list of expected return codes. The default is 0 which is successful return.
\item linesCout=-1

The expected lines of stdout. If linesCout = -1 (default), this is not checked.
\item linesCerr=-1

The expected lines of stderr. If linesCerr = -1 (default), this is not checked.
\end{enumerate}
Examples for calls of this method are in \texttt{dm\_testbench.py}.
\item startAndGetSubprocessStdout(self, argumentsList, \\
expectedReturnCode = [0], linesCout=-1, linesCerr=-1)

Start a subprocess and check the return code and the lines of stdout
and stderr. Return stdout as a list of lines.
\begin{enumerate}
\item argumentsList

The command itself with arguments as a list.
\item expectedReturnCode = [0]

The list of expected return codes. The default is 0 which is successful return.
\item linesCout=-1

The expected lines of stdout. If linesCout = -1 (default), this is not checked.
\item linesCerr=-1

The expected lines of stderr. If linesCerr = -1 (default), this is not checked.
\end{enumerate}
\item startAndGetSubprocessOutput(self, argumentsList, \\
expectedReturnCode = [-1], linesCout=-1, linesCerr=-1)

Start a subprocess and check the return code and the lines of stdout
and stderr. The output on stdout or stderr is return as a list of two
lists of lines.
\begin{enumerate}
\item argumentsList

The command itself with arguments as a list.
\item expectedReturnCode = [0]

The list of expected return codes. The default is 0 which is successful return.
\item linesCout=-1

The expected lines of stdout. If linesCout = -1 (default), this is not checked.
\item linesCerr=-1

The expected lines of stderr. If linesCerr = -1 (default), this is not checked.
\end{enumerate}
\item removePaintedFlags(self, dotLines)

From the dotLines remove all which indicates that a node is visited.
This ist needed for the comparison with expected output. In the flags
attribute, flags="0xnnnnn1nn" is replaced by flags="0xnnnnn0nn". In addition,
fillcolor green ist replaced by white and other layout attributes are
deleted. dotLines is created from 'dm-sched -o output-file'. Method
is used by compareExpectedResult and compareExpectedOutput.
\item compareExpectedResult(self, fileCurrent, fileExpected, exclude='')

Compare two dot files. fileCurrent is the file from the current test run.
fileExpected is the file with the expected result. exclude may contain
a word. If this word occures in a line of the current file, this line is
removed before the comparison. Next step is to remove the 'painted flag'
from the current file. Assert that a unified diff has no lines.
\item compareExpectedOutput(self, output, fileExpected, exclude='', \\
excludeField='', delete=[])

Compare the output from the current test run with the
fileExpected which is the file with the expected result. exclude may contain
a word. If this word occures in a line of the current file, this line is
removed before the comparison. Next step is to remove the lines numbered
in the list 'delete' from the current output and the expected file.
Next step is to remove the rest of the line when 'excludeField' is found
in a line. This is used to remove timestamps from the current output and
the expected file. Last step is to remove the 'painted flag'
from the current output. Assert that a unified diff has no lines.
\item getSnoopCommand(self, duration)

Get the snoop command with the duration given in seconds.

\item getResetCommand(self)

Get the eb-reset command. If eb-reset exists in the repository or
workspace, this file name is returned. Otherwise 'eb-reset' is returned,
which assumes that eb-reset is installed.

\item snoopToCsv(self, csvFileName, duration=1)

Run the snoop command for duration seconds and store the output in
csvFileName. Since the duration of saft-ctl snoop is measured in seconds,
but not fractions of a second, the duration is an integer.
\item snoopToCsvWithAction(self, csvFileName, action, duration=1)

Run the snoop command for duration seconds and store the output in
csvFileName. Since the duration of saft-ctl snoop is measured in seconds,
but not fractions of a second, the duration is an integer.

While snoop runs in a separate thread, the method 'action' is called.
This method should return before snoop ends.
\item analyseFrequencyFromCsv(self, csvFileName, column = 20, printTable
 = True, checkValues = dict())

Analyse a file output of 'saft-ctl snoop' as a csv file.
\begin{enumerate}
\item csvFileName

The file name of the csv file.
\item column

The number of the column to analyse. Default column is 20 (parameter of
the timing message). Column for EVTNO is 8.
\item printTable

If True, the occurrences of all values in 'column' are printed.
\item checkValues

checkValues is a dictionary of key-value pairs to check. Key is a value
in the column and value is the required frequency.
The value can be '$>$n', '$<$n', '=n', 'n' (which is the same as '=n'), '=0'.
The syntax '$<$n' fails if there are no occurrences.
Checks for intevalls are not possible since checkValues is a dictionary
and keys occur at most once.
Example: column=8 and checkValues={('0x0001', 62)} checks that EVTNO 0x0001
occurs in 62 lines of the file to analyse.
Example: column=8 and checkValues={('0x0002', '$>$0')} checks that EVTNO 0x0002
occurs at least once in the file to analyse.
Example: column=4 and checkValues={'0x7': '=0'} checks that FID 0x7 does
NOT occur in the file to analyse.
\end{enumerate}
\item analyseDmCmdOutput(self, threadsToCheck=0)

Run 'dm-cmd' with default action which shows the running threads and
the message counts. threadsToCheck is a string of 0 and 1.
For 8 threads and 4 CPUs, the string is 32 chars long.
For 32 threads and 4 CPUs, the string is 128 chars long.
A thread is considered running if the output line for that thread contains 'yes'.
A list of (key, message counts) is returned. Keys of this list are numbers xy,
where x is the CPU number, y is the thread number, both single digits.
If a thread hangs, dm-cmd may show 'yes' for this thread running, but the
thread is in undefined status. To avoid this, use the method 'checkRunningThreadsCmd'.

\item checkRunningThreadsCmd(self, messageInterval=1.0)

Use analyseDmCmdOutput twice with a delay of messageInterval in between.
Assert that the message counts increase with the second call and are greater
than 0 on the first call.

\item getQuantity(self, line)
Get the quantity of command executions from the output line
of 'dm-cmd $<$datamaster$>$ queue -v $<$block name$>$'.
    Search for 'Qty: ' in the line and parse the number.

\item checkQueueFlushed(self, queuesToFlush, blockName, flushPrio, checkFlush=True)
Check that a flush command is executed and the defined queues are flushed.
\begin{enumerate}
\item queuesToFlush: binary value between 0 and 7 for the queues to flush.
\item blockName: name of the block with the queues to check.
\item flushPrio: priority of the flush command. Defines the queue where to look for the flush command.
Priority queues higher than the flushPrio are not affected by the flush command since these
queues are empty when a flush command with lower priority is executed. Therefore queuesToFlush is changed for
\item flushprio = 0, 1.
The check for the executed flush command and the checks for the flushed queues are independant. All checks
are done in one parse run of the output of 'dm-cmd $<$datamaster$>$ -v queue $<$blockName$>$'. Flags and counters
are used to signal the section inside the output.
\item checkFlush = False means: check that no flush is executed.
\end{enumerate}

\item delay(self, duration)

Sleep for 'duration' seconds. 'duration' is a float.

\item runThreadXCommand(self, cpu, thread, command)

Test for one CPU and one thread with 'command'.
Check the return code of 0 for success and one line of output on stdout.

\item prepareRunThreads(self, cpus=15):

Check that no thread runs on the CPUs given by 'cpus' (bit mask).
Load schedules (see \ref{fig:pps-cpu0}) into datamaster, one for each CPU and start all threads.
Check that these are running. By default cpus=15, all CPUs are used.
    \begin{figure}
        \centering
        \includegraphics*[width=0.95\textwidth,keepaspectratio]{TestPattern/pps-all-threads-cpu0.pdf}
        \caption{Schedule with 8 PPS pattern to run 8 threads on one CPU used in method prepareRunThreads}
        \label{fig:pps-cpu0}
    \end{figure}

\item deleteFile(self, fileName)

Delete the file with name 'fileName'.

\item resetAllCpus(self):

Reset each CPU (loop over all lm32 CPUs). Use eb-reset $<$datamaster$>$ cpureset $<$cpu$>$.

\item listFromBits(self, bits, quantity) $->$ list

Convert 'bits', given as a string or an int, into a list of
int items. quantity is the maximal int + 1.

\item bitCount(self, bits, quantity) $->$ int

Count how many bits are 1 in the number 'bits'.
This is the number of items enabled in 'bits'.

\item printStdOutStdErr(self, lines)

Print the lines of stdout and stderr. This is given as a list of
two lists of lines.

\item getThreadQuantityFromFirmware(self) $->$ int

This class method uses 'eb-info -w' to get the thread quantity
from the lm32 firmware. This method is used once in the set up of
a class by setUpClass.

\item logToFile(self, text, fileName)

This class method logs a text to a fileName. The text is prefixed
by the current test name. This is appended to the file.

\item checkRunningThreads(self, lines, masks) $->$ str

Check the hex numbers describing the running threads.
Since in some cases it is not determined which thread is used for a
command, we have to check the lines against multiple masks.
\begin{enumerate}
\item lines is a list of lines, describes the running threads.
\item masks is a list (not a set!) of hex numbers as strings.
\end{enumerate}
    Each number describes an allowed pattern of running threads.
\end{enumerate}

\section{Structure of Description}
\begin{enumerate}
  \item Purpose of Test

  What is the objective of this test?
  \item Prerequisites of Test

  What is the setting of the test?
  \item Test Actions

  List the actions of the test. This includes the graphs of the test pattern.
  \item Success Criteria

  What is checked to state a successful test?
\end{enumerate}
\end{document}
